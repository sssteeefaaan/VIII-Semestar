{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Januar 2022"
      ],
      "metadata": {
        "id": "9EAF1A2SqhMH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "443mcksibRm7"
      },
      "outputs": [],
      "source": [
        "%%writefile jan_2022.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__host__ void initialize_vector(int** A, int n);\n",
        "__host__ void operate_on_GPU(int* A, int* B, int n);\n",
        "__global__ void kernel(int* A, int* B, int n);\n",
        "__host__ bool check_result(int*A, int*B, int n);\n",
        "__host__ void print_vector(const char* lbl, int* A, int n);\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int n, *A, *B;\n",
        "    n = (1 << 15) + 25;\n",
        " \n",
        "    initialize_vector(&A, n);\n",
        "    B = (int*) malloc(sizeof(int) * (n - 2));\n",
        "\n",
        "    operate_on_GPU(A, B, n);\n",
        " \n",
        "    print_vector(\"B\", B, n - 2);\n",
        "\n",
        "    if(check_result(A, B, n))\n",
        "      cout << \"Correct!\" << endl;\n",
        "    else\n",
        "      cout << \"False!\" << endl;\n",
        "}\n",
        "\n",
        "\n",
        "__host__ void initialize_vector(int** A, int n)\n",
        "{\n",
        "    *A = (int*)malloc(sizeof(int) * n);\n",
        "    for(int i = 0; i < n; i++)\n",
        "      (*A)[i] = i + 1;\n",
        "}\n",
        "\n",
        "__host__ void operate_on_GPU(int* A, int* B, int n)\n",
        "{\n",
        "    int* dev_A, *dev_B;\n",
        "    size_t full = sizeof(int) * n,\n",
        "            part = sizeof(int) * (n - 2);\n",
        "\n",
        "    cudaError_t err;\n",
        " \n",
        "    err = cudaMalloc(&dev_A, full);\n",
        "    if(err)\n",
        "      cout << \"1A \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    err = cudaMalloc(&dev_B, part);\n",
        "    if(err)\n",
        "          cout << \"1B \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    err = cudaMemcpy(dev_A, A, full, cudaMemcpyHostToDevice);\n",
        "    if(err)\n",
        "          cout << \"2 \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    kernel<<<min(256, n / BLOCK_SIZE + 1), BLOCK_SIZE>>>(dev_A, dev_B, n);\n",
        "\n",
        "    err = cudaMemcpy(B, dev_B, part, cudaMemcpyDeviceToHost);\n",
        "    if(err)\n",
        "          cout << \"3 \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_A);\n",
        "}\n",
        "\n",
        "__global__ void kernel(int* A, int* B, int n)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    __shared__ int sh[BLOCK_SIZE];\n",
        " \n",
        "    while(tid < n - 1)\n",
        "    {\n",
        "        sh[threadIdx.x] = A[tid + 1];\n",
        "        __syncthreads();\n",
        "     \n",
        "        if(tid < n - 2)\n",
        "        {\n",
        "          if(threadIdx.x == 0)\n",
        "            B[tid] = (A[tid] + sh[threadIdx.x] + sh[threadIdx.x + 1]) / 3;\n",
        "          else if(threadIdx.x == (blockDim.x - 1))\n",
        "            B[tid] = (sh[threadIdx.x - 1] + sh[threadIdx.x] + A[tid + 2]) / 3;\n",
        "          else\n",
        "            B[tid] = (sh[threadIdx.x - 1] + sh[threadIdx.x] + sh[threadIdx.x + 1]) / 3;\n",
        "        }\n",
        "     \n",
        "        __syncthreads();\n",
        "     \n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "\n",
        "__host__ bool check_result(int*A, int*B, int n)\n",
        "{\n",
        "    bool c = true;\n",
        "    for(int i = 0; c && i < n - 2; i++)\n",
        "      c = B[i] == ((A[i] + A[i + 1] + A[i + 2]) / 3);\n",
        "    return c;\n",
        "}\n",
        "\n",
        "__host__ void print_vector(const char* lbl, int* A, int n)\n",
        "{\n",
        "    cout << lbl << \" = |\\t\";\n",
        "    for(int i = 0; i < n; (cout << A[i++] << \"\\t\"));\n",
        "    cout << \"|\\n\";\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"jan_2022.cu\"  #@param { type: \"string\" }\n",
        "compiled_filepath = \"jan_2022\"  #@param { type: \"string\" }\n",
        "\n",
        "!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 $filepath -o $compiled_filepath\n",
        "\n",
        "argv = \"\" #@param [] { allow-input: true }\n",
        "\n",
        "!./$compiled_filepath $argv"
      ],
      "metadata": {
        "id": "iSGfILV7i0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jun 2 2021\n",
        "# Ovo je takav overkill, ali ja sam Stefan :D"
      ],
      "metadata": {
        "id": "RwMuu9sHqnW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile jun2_2021.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "\n",
        "__host__ void initialize_vector(int** A, int n);\n",
        "__host__ void operate_on_GPU(int* A, int* B, int* v, int n, int m);\n",
        "__global__ void kernel_sum(int* A, int* B, int* v, int n, int m);\n",
        "__global__ void kernel_reduce(int* v, int n, int m, int el_numb);\n",
        "__host__ bool check_result(int*A, int*B, int *v, int n, int m);\n",
        "__host__ void print_vector(const char* lbl, int* A, int n);\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int n, m, *A, *B, *v;\n",
        "    n = 221;\n",
        "    m = 123;\n",
        " \n",
        "    initialize_vector(&A, n * m);\n",
        "    initialize_vector(&B, n * m);\n",
        "    v = (int*) malloc(sizeof(int) * n);\n",
        "\n",
        "    operate_on_GPU(A, B, v, n, m);\n",
        " \n",
        "    print_vector(\"v\", v, n);\n",
        "\n",
        "    if(check_result(A, B, v, n, m))\n",
        "      cout << \"Correct!\" << endl;\n",
        "    else\n",
        "      cout << \"False!\" << endl;\n",
        "}\n",
        "\n",
        "\n",
        "__host__ void initialize_vector(int** A, int n)\n",
        "{\n",
        "    *A = (int*)malloc(sizeof(int) * n);\n",
        "    for(int i = 0; i < n; i++)\n",
        "      (*A)[i] = i + 1;\n",
        "}\n",
        "\n",
        "__host__ void operate_on_GPU(int* A, int* B, int* v, int n, int m)\n",
        "{\n",
        "    int* dev_A, *dev_B, *dev_v;\n",
        " \n",
        "    dim3 grid_size(min(256, m / BLOCK_SIZE / 2 + 1), min(256, n / BLOCK_SIZE + 1)),\n",
        "        block_size(BLOCK_SIZE / 2, BLOCK_SIZE);\n",
        " \n",
        "    size_t full = sizeof(int) * n * m,\n",
        "            part = sizeof(int) * n * grid_size.x;\n",
        "\n",
        "    cudaError_t err;\n",
        " \n",
        "    err = cudaMalloc(&dev_A, full);\n",
        "    if(err)\n",
        "      cout << \"1A \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    err = cudaMalloc(&dev_B, full);\n",
        "    if(err)\n",
        "          cout << \"1B \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    err = cudaMalloc(&dev_v, part);\n",
        "    if(err)\n",
        "          cout << \"1v \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    err = cudaMemcpy(dev_A, A, full, cudaMemcpyHostToDevice);\n",
        "    if(err)\n",
        "          cout << \"2A \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    err = cudaMemcpy(dev_B, B, full, cudaMemcpyHostToDevice);\n",
        "    if(err)\n",
        "          cout << \"2B \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    kernel_sum<<<grid_size, block_size>>>(dev_A, dev_B, dev_v, n, m);\n",
        "    block_size.x = grid_size.x;\n",
        "    grid_size.x = 1;\n",
        "    kernel_reduce<<<grid_size, block_size>>>(dev_v, n, block_size.x, m);\n",
        "\n",
        "    err = cudaMemcpy(v, dev_v, sizeof(int) * n, cudaMemcpyDeviceToHost);\n",
        "    if(err)\n",
        "          cout << \"3 \" << cudaGetErrorString(err) << endl;\n",
        " \n",
        "    cudaFree(dev_v);\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_A);\n",
        "}\n",
        "\n",
        "__global__ void kernel_sum(int* A, int* B, int* v, int n, int m)\n",
        "{\n",
        "    int tid_x_initial = 2 * blockIdx.x * blockDim.x + threadIdx.x,\n",
        "      tid_y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    __shared__ int sh[BLOCK_SIZE][BLOCK_SIZE];\n",
        " \n",
        "    while(tid_y < n)\n",
        "    {\n",
        "        int tid_x = tid_x_initial;\n",
        "     \n",
        "        sh[threadIdx.y][threadIdx.x] = 0;\n",
        "        while(tid_x < m)\n",
        "        {\n",
        "          sh[threadIdx.y][threadIdx.x] += A[tid_y * m + tid_x] + B[tid_y * m + tid_x];\n",
        "          if(tid_x + blockDim.x < m)\n",
        "            sh[threadIdx.y][threadIdx.x] += A[tid_y * m + tid_x + blockDim.x] + B[tid_y * m + tid_x + blockDim.x];\n",
        "          tid_x += 2 * blockDim.x * gridDim.x;\n",
        "        }\n",
        "     \n",
        "        for(int i = blockDim.x>>1; i > threadIdx.x; i>>=1)\n",
        "        {\n",
        "          __syncthreads();\n",
        "          sh[threadIdx.y][threadIdx.x] += sh[threadIdx.y][threadIdx.x + i];\n",
        "        }\n",
        "     \n",
        "        if(!threadIdx.x)\n",
        "          v[tid_y * gridDim.x + blockIdx.x] = sh[threadIdx.y][0];\n",
        "     \n",
        "        tid_y += blockDim.y * gridDim.y;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void kernel_reduce(int* v, int n, int m, int el_numb)\n",
        "{\n",
        "    int tid_x_initial = 2 * blockIdx.x * blockDim.x + threadIdx.x,\n",
        "      tid_y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    __shared__ int sh[BLOCK_SIZE][BLOCK_SIZE];\n",
        " \n",
        "    while(tid_y < n)\n",
        "    {\n",
        "        int tid_x = tid_x_initial;\n",
        "     \n",
        "        sh[threadIdx.y][threadIdx.x] = 0;\n",
        "        while(tid_x < m)\n",
        "        {\n",
        "          sh[threadIdx.y][threadIdx.x] += v[tid_y * m + tid_x];\n",
        "          if(tid_x + blockDim.x < m)\n",
        "            sh[threadIdx.y][threadIdx.x] += v[tid_y * m + tid_x + blockDim.x];\n",
        "          tid_x += 2 * blockDim.x * gridDim.x;\n",
        "        }\n",
        "     \n",
        "        for(int i = blockDim.x >> 1; i > threadIdx.x; i >>= 1)\n",
        "        {\n",
        "          __syncthreads();\n",
        "          sh[threadIdx.y][threadIdx.x] += sh[threadIdx.y][threadIdx.x + i];\n",
        "        }\n",
        "     \n",
        "        if(!threadIdx.x){\n",
        "          v[tid_y * gridDim.x + blockIdx.x] = sh[threadIdx.y][0];\n",
        "          if(gridDim.x == 1)\n",
        "            v[tid_y] /= el_numb;\n",
        "        }\n",
        "     \n",
        "        tid_y += blockDim.y * gridDim.y;\n",
        "    }\n",
        "}\n",
        "\n",
        "__host__ bool check_result(int*A, int*B, int*v, int n, int m)\n",
        "{\n",
        "    bool c = true;\n",
        "    for(int i = 0; c && i < n; i++)\n",
        "    {\n",
        "        int sum = 0;\n",
        "        for(int j = 0; j < m; j++)\n",
        "          sum += A[i * m + j] + B[i * m + j];\n",
        "        c = v[i] == (sum / m);\n",
        "    }\n",
        "    return c;\n",
        "}\n",
        "\n",
        "__host__ void print_vector(const char* lbl, int* A, int n)\n",
        "{\n",
        "    cout << lbl << \" = |\\t\";\n",
        "    for(int i = 0; i < n; (cout << A[i++] << \"\\t\"));\n",
        "    cout << \"|\\n\";\n",
        "}"
      ],
      "metadata": {
        "id": "p_n4SMhQqscY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"jun2_2021.cu\"  #@param { type: \"string\" }\n",
        "compiled_filepath = \"jun2_2021\"  #@param { type: \"string\" }\n",
        "\n",
        "!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 $filepath -o $compiled_filepath\n",
        "\n",
        "argv = \"\" #@param [] { allow-input: true }\n",
        "\n",
        "!./$compiled_filepath $argv"
      ],
      "metadata": {
        "id": "ubAyZAv1s_Mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}